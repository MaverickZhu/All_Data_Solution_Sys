"""
è§†é¢‘è§†è§‰åˆ†ææœåŠ¡
åŸºäºç°æœ‰ImageDescriptionServiceï¼Œæ‰©å±•åˆ°è§†é¢‘å¸§çš„æ™ºèƒ½åˆ†æ
é›†æˆQwen2.5-VLæ¨¡å‹è¿›è¡Œåœºæ™¯ç†è§£ã€ç‰©ä½“è¯†åˆ«ã€æ–‡å­—æå–
"""
import logging
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional
import base64
import json
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage

from backend.services.video_frame_extractor import FrameInfo
from backend.services.image_description_service import ImageDescriptionService

logger = logging.getLogger("service")


class VideoVisionService:
    """
    è§†é¢‘è§†è§‰åˆ†ææœåŠ¡
    åŸºäºQwen2.5-VLæ¨¡å‹è¿›è¡Œè§†é¢‘å¸§çš„æ™ºèƒ½åˆ†æ
    """
    
    def __init__(self, 
                 model_name: str = "qwen2.5vl:7b", 
                 ollama_url: str = "http://host.docker.internal:11435"):
        self.model_name = model_name
        self.ollama_url = ollama_url
        self.image_service = ImageDescriptionService(model_name, ollama_url)
        logger.info(f"ğŸ¬ è§†é¢‘è§†è§‰åˆ†ææœåŠ¡åˆå§‹åŒ–: {model_name}")
    
    async def analyze_video_frames(self, frames: List[FrameInfo]) -> Dict[str, Any]:
        """
        åˆ†æè§†é¢‘å¸§åºåˆ—ï¼Œæå–è§†è§‰è¯­ä¹‰ä¿¡æ¯
        é‡æ–°è®¾è®¡ï¼šè§£å†³LLMè°ƒç”¨é˜»å¡é—®é¢˜ï¼Œè€Œéç®€å•çš„æ—¶é—´é™åˆ¶
        
        Args:
            frames: è§†é¢‘å¸§ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            è§†é¢‘è§†è§‰åˆ†æç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹åˆ†æ {len(frames)} ä¸ªè§†é¢‘å¸§")
            
            # åˆ†æç»“æœå®¹å™¨
            frame_analyses = []
            visual_themes = set()
            detected_objects = set()
            scene_types = set()
            text_contents = []
            failed_frames = []
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = asyncio.get_event_loop().time()
            
            # ä¼˜åŒ–çš„æ‰¹å¤„ç†ç­–ç•¥ï¼šçœŸæ­£çš„å¹¶å‘å¤„ç†
            max_concurrent = 1  # å•çº¿ç¨‹å¤„ç†ï¼Œé¿å…GPUèµ„æºç«äº‰
            semaphore = asyncio.Semaphore(max_concurrent)
            
            async def analyze_frame_safe(frame: FrameInfo, frame_index: int) -> Optional[Dict[str, Any]]:
                """å®‰å…¨çš„å¸§åˆ†æå‡½æ•°ï¼ŒåŒ…å«è¿æ¥æ£€æŸ¥å’Œé‡è¯•æœºåˆ¶"""
                async with semaphore:
                    try:
                        # åœ¨æ¯æ¬¡åˆ†æå‰æ£€æŸ¥Ollamaè¿æ¥çŠ¶æ€
                        if not await self._check_ollama_health():
                            logger.warning(f"å¸§ {frame.frame_number}: OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡åˆ†æ")
                            return None
                        
                        logger.info(f"[{frame_index+1}/{len(frames)}] åˆ†æå¸§ {frame.frame_number} (æ—¶é—´: {frame.timestamp:.2f}s)")
                        
                        # ä½¿ç”¨æ”¹è¿›çš„åˆ†ææ–¹æ³•
                        result = await self._analyze_frame_resilient(frame)
                        
                        if result and not isinstance(result, str):  # ç¡®ä¿è¿”å›æœ‰æ•ˆç»“æœ
                            logger.info(f"å¸§ {frame.frame_number} åˆ†ææˆåŠŸ")
                            return result
                        else:
                            logger.warning(f"å¸§ {frame.frame_number} åˆ†æè¿”å›æ— æ•ˆç»“æœ")
                            return None
                            
                    except Exception as e:
                        logger.error(f"å¸§ {frame.frame_number} åˆ†æå¼‚å¸¸: {e}")
                        failed_frames.append({
                            "frame_number": frame.frame_number,
                            "error": str(e),
                            "timestamp": frame.timestamp
                        })
                        return None
            
            # ä¸²è¡Œå¤„ç†æ¯ä¸€å¸§ï¼Œé¿å…èµ„æºç«äº‰å’Œè¿æ¥é˜»å¡
            for i, frame in enumerate(frames):
                try:
                    result = await analyze_frame_safe(frame, i)
                    
                    if result:
                        frame_analyses.append(result)
                        
                        # æ”¶é›†å…¨å±€ä¿¡æ¯
                        if result.get('visual_themes'):
                            visual_themes.update(result['visual_themes'])
                        if result.get('detected_objects'):
                            detected_objects.update(result['detected_objects'])
                        if result.get('scene_type'):
                            scene_types.add(result['scene_type'])
                        if result.get('text_content'):
                            text_contents.append(result['text_content'])
                    
                    # å®šæœŸæŠ¥å‘Šè¿›åº¦ï¼ˆæ¯å¤„ç†5å¸§ï¼‰
                    if (i + 1) % 5 == 0 or i == len(frames) - 1:
                        progress = (i + 1) / len(frames) * 100
                        elapsed = asyncio.get_event_loop().time() - start_time
                        logger.info(f"è¿›åº¦: {progress:.1f}% ({i+1}/{len(frames)}), è€—æ—¶: {elapsed:.1f}s")
                    
                    # æ¯å¤„ç†å®Œä¸€å¸§ï¼ŒçŸ­æš‚ä¼‘æ¯é¿å…è¿‡è½½
                    if i < len(frames) - 1:
                        await asyncio.sleep(0.2)
                        
                except Exception as e:
                    logger.error(f"å¤„ç†å¸§ {frame.frame_number} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    failed_frames.append({
                        "frame_number": frame.frame_number,
                        "error": f"å¤„ç†é”™è¯¯: {str(e)}",
                        "timestamp": frame.timestamp
                    })
                    continue
            
            # ç”Ÿæˆè§†é¢‘çº§åˆ«çš„åˆ†ææ‘˜è¦
            try:
                if frame_analyses:
                    video_summary = await self._generate_video_summary_safe(frame_analyses)
                else:
                    video_summary = "æ‰€æœ‰å¸§åˆ†æå¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè§†é¢‘æ‘˜è¦"
            except Exception as e:
                logger.warning(f"è§†é¢‘æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
                video_summary = f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"
            
            # æ£€æµ‹åœºæ™¯å˜åŒ–
            try:
                scene_changes = self._detect_scene_changes(frame_analyses)
            except Exception as e:
                logger.warning(f"åœºæ™¯å˜åŒ–æ£€æµ‹å¤±è´¥: {e}")
                scene_changes = []
            
            # è®¡ç®—æˆåŠŸç‡
            total_attempted = len(frames)
            successful_analyses = len(frame_analyses)
            success_rate = successful_analyses / total_attempted if total_attempted > 0 else 0
            total_time = asyncio.get_event_loop().time() - start_time
            
            analysis_result = {
                "total_frames_analyzed": successful_analyses,
                "total_frames_attempted": total_attempted,
                "failed_frames": failed_frames,
                "frame_analyses": frame_analyses,
                "visual_themes": list(visual_themes),
                "detected_objects": list(detected_objects),
                "scene_types": list(scene_types),
                "extracted_text": text_contents,
                "scene_changes": scene_changes,
                "video_summary": video_summary,
                "analysis_metadata": {
                    "model_used": self.model_name,
                    "analysis_type": "video_vision_semantic_resilient",
                    "success_rate": round(success_rate, 3),
                    "processing_time": round(total_time, 1),
                    "frames_per_second": round(successful_analyses / total_time, 2) if total_time > 0 else 0,
                    "failure_count": len(failed_frames),
                    "avg_time_per_frame": round(total_time / total_attempted, 2) if total_attempted > 0 else 0
                }
            }
            
            logger.info(f"è§†é¢‘è§†è§‰åˆ†æå®Œæˆ: {successful_analyses}/{total_attempted}å¸§æˆåŠŸï¼ŒæˆåŠŸç‡: {success_rate:.1%}ï¼Œæ€»è€—æ—¶: {total_time:.1f}s")
            return analysis_result
            
        except Exception as e:
            logger.error(f"è§†é¢‘è§†è§‰åˆ†æå®Œå…¨å¤±è´¥: {e}")
            return {
                "error": str(e),
                "total_frames_analyzed": 0,
                "total_frames_attempted": len(frames) if frames else 0,
                "failed_frames": [{"error": f"å…¨å±€å¤±è´¥: {str(e)}"}],
                "frame_analyses": [],
                "visual_themes": [],
                "detected_objects": [],
                "scene_types": [],
                "extracted_text": [],
                "scene_changes": [],
                "video_summary": f"åˆ†æå¤±è´¥: {str(e)}",
                "analysis_metadata": {
                    "model_used": self.model_name,
                    "analysis_type": "video_vision_semantic_resilient",
                    "success_rate": 0,
                    "error": str(e)
                }
            }
    
    async def analyze_single_frame(self, frame: FrameInfo) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªè§†é¢‘å¸§
        
        Args:
            frame: å¸§ä¿¡æ¯
            
        Returns:
            å•å¸§åˆ†æç»“æœ
        """
        try:
            frame_path = Path(frame.frame_path)
            if not frame_path.exists():
                raise FileNotFoundError(f"å¸§æ–‡ä»¶ä¸å­˜åœ¨: {frame_path}")
            
            logger.debug(f"åˆ†æå¸§: {frame.frame_number} (æ—¶é—´: {frame.timestamp:.2f}s)")
            
            # ä½¿ç”¨ä¸“é—¨çš„è§†é¢‘å¸§åˆ†ææç¤º
            analysis_result = await self._analyze_frame_with_video_context(frame_path, frame)
            
            # è§£æåˆ†æç»“æœ
            parsed_result = self._parse_frame_analysis(analysis_result, frame)
            
            return parsed_result
            
        except Exception as e:
            logger.error(f"å•å¸§åˆ†æå¤±è´¥ (å¸§{frame.frame_number}): {e}")
            return {
                "frame_number": frame.frame_number,
                "timestamp": frame.timestamp,
                "error": str(e),
                "visual_themes": [],
                "detected_objects": [],
                "scene_type": "unknown",
                "text_content": "",
                "description": "",
                "confidence": 0.0
            }
    
    async def _analyze_frame_with_video_context(self, frame_path: Path, frame: FrameInfo) -> str:
        """
        ä½¿ç”¨è§†é¢‘ä¸Šä¸‹æ–‡åˆ†æå¸§ - å¢å¼ºè¶…æ—¶æ§åˆ¶å’Œé”™è¯¯æ¢å¤
        """
        max_retries = 3
        retry_count = 0
        base_timeout = 20  # åŸºç¡€è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        while retry_count < max_retries:
            try:
                # åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´
                current_timeout = base_timeout + (retry_count * 10)  # é‡è¯•æ—¶å¢åŠ è¶…æ—¶æ—¶é—´
                
                logger.debug(f"åˆ†æå¸§ {frame.frame_number}ï¼Œå°è¯• {retry_count + 1}/{max_retries}ï¼Œè¶…æ—¶: {current_timeout}s")
                
                # ç¼–ç å›¾åƒ
                image_base64 = self.image_service.encode_image_to_base64(frame_path)
                
                # åˆå§‹åŒ–LLM with strict timeout
                llm = ChatOllama(
                    base_url=self.ollama_url,
                    model=self.model_name,
                    temperature=0.1,
                    timeout=current_timeout,  # åŠ¨æ€è¶…æ—¶
                    # æ·»åŠ æ›´å¤šæ§åˆ¶å‚æ•°
                    request_timeout=current_timeout,
                    num_predict=512  # é™åˆ¶ç”Ÿæˆé•¿åº¦
                )
                
                # ç®€åŒ–çš„è§†é¢‘å¸§åˆ†ææç¤º - å‡å°‘å¤æ‚æ€§é¿å…å¡é¡¿
                prompt_template = f"""åˆ†æå¸§{frame.frame_number}(æ—¶é—´{frame.timestamp:.1f}s):
è¿”å›JSONæ ¼å¼:
{{
    "scene_type": "åœºæ™¯ç±»å‹",
    "main_objects": ["ç‰©ä½“1", "ç‰©ä½“2"],
    "description": "ç®€çŸ­æè¿°(30å­—å†…)",
    "confidence": 0.8
}}
ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šï¼Œåªè¿”å›JSONã€‚"""
                
                # æ„å»ºæ¶ˆæ¯
                messages = [
                    HumanMessage(
                        content=[
                            {"type": "text", "text": prompt_template},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                        ]
                    )
                ]
                
                # ä½¿ç”¨asyncio.wait_foræ·»åŠ é¢å¤–çš„è¶…æ—¶ä¿æŠ¤
                response = await asyncio.wait_for(
                    llm.ainvoke(messages),
                    timeout=current_timeout + 5  # é¢å¤–5ç§’ç¼“å†²
                )
                
                analysis_text = response.content
                
                # éªŒè¯å“åº”ä¸ä¸ºç©º
                if not analysis_text or len(analysis_text.strip()) < 10:
                    raise ValueError("LLMè¿”å›å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")
                
                logger.debug(f"å¸§ {frame.frame_number} åˆ†ææˆåŠŸ")
                return analysis_text
                
            except asyncio.TimeoutError:
                retry_count += 1
                error_msg = f"å¸§ {frame.frame_number} åˆ†æè¶…æ—¶ (è¶…æ—¶æ—¶é—´: {current_timeout}s)"
                logger.warning(error_msg)
                
                if retry_count >= max_retries:
                    logger.error(f"å¸§ {frame.frame_number} æœ€ç»ˆåˆ†æå¤±è´¥: è¶…æ—¶")
                    # è¿”å›ç®€åŒ–çš„é»˜è®¤ç»“æœï¼Œé¿å…å®Œå…¨å¤±è´¥
                    return self._get_fallback_analysis(frame)
                
                # çŸ­æš‚å»¶è¿Ÿåé‡è¯•
                await asyncio.sleep(2)
                
            except Exception as e:
                retry_count += 1
                logger.warning(f"å¸§ {frame.frame_number} åˆ†æå¤±è´¥ (å°è¯• {retry_count}/{max_retries}): {e}")
                
                if retry_count >= max_retries:
                    logger.error(f"å¸§ {frame.frame_number} æœ€ç»ˆåˆ†æå¤±è´¥: {e}")
                    return self._get_fallback_analysis(frame)
                
                # çŸ­æš‚å»¶è¿Ÿåé‡è¯•
                await asyncio.sleep(1)
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ
        return self._get_fallback_analysis(frame)
    
    def _get_fallback_analysis(self, frame: FrameInfo) -> str:
        """
        ç”Ÿæˆå…œåº•åˆ†æç»“æœï¼Œé¿å…ä»»åŠ¡å®Œå…¨å¤±è´¥
        """
        fallback_result = {
            "scene_type": "æœªçŸ¥åœºæ™¯",
            "main_objects": ["è§†é¢‘å¸§"],
            "description": f"ç¬¬{frame.frame_number}å¸§(æ—¶é—´{frame.timestamp:.1f}s)",
            "confidence": 0.1
        }
        return json.dumps(fallback_result, ensure_ascii=False)
    
    def _parse_frame_analysis(self, analysis_text: str, frame: FrameInfo) -> Dict[str, Any]:
        """
        è§£æå¸§åˆ†æç»“æœ
        """
        try:
            # å°è¯•è§£æJSON
            import re
            
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                analysis_data = json.loads(json_str)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œåˆ›å»ºé»˜è®¤ç»“æ„
                analysis_data = self._create_fallback_analysis(analysis_text)
            
            # æ ‡å‡†åŒ–ç»“æœæ ¼å¼
            result = {
                "frame_number": frame.frame_number,
                "timestamp": frame.timestamp,
                "scene_type": analysis_data.get("scene_type", "unknown"),
                "detected_objects": analysis_data.get("detected_objects", []),
                "visual_themes": analysis_data.get("visual_themes", []),
                "text_content": analysis_data.get("text_content", ""),
                "description": analysis_data.get("description", ""),
                "activity_level": analysis_data.get("activity_level", "unknown"),
                "lighting_condition": analysis_data.get("lighting_condition", "unknown"),
                "composition": analysis_data.get("composition", "unknown"),
                "color_tone": analysis_data.get("color_tone", "unknown"),
                "confidence": float(analysis_data.get("confidence", 0.5)),
                "quality_metrics": {
                    "brightness": frame.brightness,
                    "contrast": frame.contrast,
                    "sharpness": frame.sharpness
                },
                "key_frame_reason": frame.key_frame_reason
            }
            
            return result
            
        except Exception as e:
            logger.warning(f"è§£æå¸§åˆ†æç»“æœå¤±è´¥: {e}")
            return self._create_fallback_analysis(analysis_text, frame)
    
    def _create_fallback_analysis(self, text: str, frame: FrameInfo = None) -> Dict[str, Any]:
        """
        åˆ›å»ºåå¤‡åˆ†æç»“æœ
        """
        return {
            "frame_number": frame.frame_number if frame else 0,
            "timestamp": frame.timestamp if frame else 0.0,
            "scene_type": "unknown",
            "detected_objects": [],
            "visual_themes": [],
            "text_content": "",
            "description": text[:100] if text else "åˆ†æå¤±è´¥",
            "activity_level": "unknown",
            "lighting_condition": "unknown", 
            "composition": "unknown",
            "color_tone": "unknown",
            "confidence": 0.3,
            "quality_metrics": {
                "brightness": frame.brightness if frame else 0.0,
                "contrast": frame.contrast if frame else 0.0,
                "sharpness": frame.sharpness if frame else 0.0
            },
            "key_frame_reason": frame.key_frame_reason if frame else ""
        }
    
    def _detect_scene_changes(self, frame_analyses: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹åœºæ™¯å˜åŒ–
        """
        scene_changes = []
        
        if len(frame_analyses) < 2:
            return scene_changes
        
        prev_scene = None
        for analysis in frame_analyses:
            current_scene = analysis.get("scene_type", "unknown")
            
            if prev_scene and prev_scene != current_scene:
                scene_changes.append({
                    "timestamp": analysis.get("timestamp", 0.0),
                    "frame_number": analysis.get("frame_number", 0),
                    "from_scene": prev_scene,
                    "to_scene": current_scene,
                    "change_type": "scene_transition"
                })
            
            prev_scene = current_scene
        
        return scene_changes
    
    async def _generate_video_summary(self, frame_analyses: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆè§†é¢‘çº§åˆ«çš„åˆ†ææ‘˜è¦
        """
        try:
            if not frame_analyses:
                return "æ— æ³•ç”Ÿæˆæ‘˜è¦ï¼šæ²¡æœ‰æˆåŠŸåˆ†æçš„å¸§"
            
            # æ”¶é›†å…³é”®ä¿¡æ¯
            scene_types = [f.get("scene_type", "unknown") for f in frame_analyses]
            descriptions = [f.get("description", "") for f in frame_analyses if f.get("description")]
            
            # ç»Ÿè®¡æœ€å¸¸è§çš„åœºæ™¯ç±»å‹
            from collections import Counter
            scene_counter = Counter(scene_types)
            dominant_scene = scene_counter.most_common(1)[0][0] if scene_counter else "unknown"
            
            # ç”Ÿæˆç®€å•æ‘˜è¦
            summary = f"è§†é¢‘ä¸»è¦åœºæ™¯ç±»å‹ï¼š{dominant_scene}ã€‚"
            
            if len(descriptions) > 0:
                # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æè¿°
                sample_descriptions = descriptions[:3]
                summary += f"å…³é”®åœºæ™¯ï¼š{'; '.join(sample_descriptions)}ã€‚"
            
            summary += f"å…±åˆ†æ {len(frame_analyses)} ä¸ªå…³é”®å¸§ã€‚"
            
            return summary
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆè§†é¢‘æ‘˜è¦å¤±è´¥: {e}")
            return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"
    
    async def analyze_scene_sequence(self, frames: List[FrameInfo]) -> Dict[str, Any]:
        """
        åˆ†æåœºæ™¯åºåˆ—ï¼Œè¯†åˆ«è§†é¢‘çš„æ•…äº‹ç»“æ„
        """
        try:
            logger.info("å¼€å§‹åœºæ™¯åºåˆ—åˆ†æ...")
            
            # å…ˆè¿›è¡ŒåŸºç¡€å¸§åˆ†æ
            frame_results = await self.analyze_video_frames(frames)
            
            if not frame_results.get("frame_analyses"):
                return {"error": "æ²¡æœ‰æˆåŠŸåˆ†æçš„å¸§"}
            
            # åˆ†æåœºæ™¯åºåˆ—
            sequences = self._identify_scene_sequences(frame_results["frame_analyses"])
            
            # åˆ†ææ•…äº‹ç»“æ„
            story_structure = self._analyze_story_structure(sequences)
            
            return {
                "scene_sequences": sequences,
                "story_structure": story_structure,
                "total_scenes": len(sequences),
                "analysis_metadata": {
                    "model_used": self.model_name,
                    "analysis_type": "scene_sequence"
                }
            }
            
        except Exception as e:
            logger.error(f"åœºæ™¯åºåˆ—åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _identify_scene_sequences(self, frame_analyses: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        è¯†åˆ«åœºæ™¯åºåˆ—
        """
        sequences = []
        current_sequence = None
        
        for analysis in frame_analyses:
            scene_type = analysis.get("scene_type", "unknown")
            timestamp = analysis.get("timestamp", 0.0)
            
            if current_sequence is None or current_sequence["scene_type"] != scene_type:
                # å¼€å§‹æ–°åºåˆ—
                if current_sequence:
                    current_sequence["end_time"] = prev_timestamp
                    current_sequence["duration"] = current_sequence["end_time"] - current_sequence["start_time"]
                    sequences.append(current_sequence)
                
                current_sequence = {
                    "scene_type": scene_type,
                    "start_time": timestamp,
                    "start_frame": analysis.get("frame_number", 0),
                    "frames": [analysis]
                }
            else:
                # ç»§ç»­å½“å‰åºåˆ—
                current_sequence["frames"].append(analysis)
            
            prev_timestamp = timestamp
        
        # æ·»åŠ æœ€åä¸€ä¸ªåºåˆ—
        if current_sequence:
            current_sequence["end_time"] = prev_timestamp
            current_sequence["duration"] = current_sequence["end_time"] - current_sequence["start_time"]
            sequences.append(current_sequence)
        
        return sequences
    
    def _analyze_story_structure(self, sequences: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†ææ•…äº‹ç»“æ„
        """
        if not sequences:
            return {"structure": "unknown", "phases": []}
        
        total_duration = sum(seq.get("duration", 0) for seq in sequences)
        
        # ç®€å•çš„ä¸‰æ®µå¼ç»“æ„åˆ†æ
        structure_phases = []
        cumulative_time = 0
        
        for i, seq in enumerate(sequences):
            duration = seq.get("duration", 0)
            cumulative_time += duration
            progress = cumulative_time / total_duration if total_duration > 0 else 0
            
            if progress <= 0.33:
                phase = "å¼€å§‹"
            elif progress <= 0.66:
                phase = "å‘å±•"
            else:
                phase = "ç»“å°¾"
            
            structure_phases.append({
                "sequence_index": i,
                "scene_type": seq.get("scene_type", "unknown"),
                "phase": phase,
                "start_time": seq.get("start_time", 0),
                "duration": duration,
                "progress": progress
            })
        
        return {
            "structure": "ä¸‰æ®µå¼",
            "phases": structure_phases,
            "total_duration": total_duration,
            "scene_count": len(sequences)
        }

    async def _check_ollama_health(self) -> bool:
        """
        æ£€æŸ¥OllamaæœåŠ¡å¥åº·çŠ¶æ€
        """
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.ollama_url}/api/tags", timeout=aiohttp.ClientTimeout(total=5)) as response:
                    if response.status == 200:
                        data = await response.json()
                        models = [model['name'] for model in data.get('models', [])]
                        available = self.model_name in models
                        if not available:
                            logger.warning(f"æ¨¡å‹ {self.model_name} åœ¨Ollamaä¸­ä¸å¯ç”¨ï¼Œå¯ç”¨æ¨¡å‹: {models}")
                        return available
                    else:
                        logger.warning(f"OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status}")
                        return False
        except Exception as e:
            logger.error(f"Ollamaå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def _analyze_frame_resilient(self, frame: FrameInfo) -> Optional[Dict[str, Any]]:
        """
        å¼¹æ€§çš„å¸§åˆ†ææ–¹æ³•ï¼ŒåŒ…å«è¿æ¥é‡è¯•å’Œé”™è¯¯æ¢å¤
        """
        max_attempts = 2  # å‡å°‘é‡è¯•æ¬¡æ•°ï¼Œé¿å…æ— é™å¾ªç¯
        
        for attempt in range(max_attempts):
            try:
                frame_path = Path(frame.frame_path)
                if not frame_path.exists():
                    logger.error(f"å¸§æ–‡ä»¶ä¸å­˜åœ¨: {frame_path}")
                    return None
                
                logger.debug(f"åˆ†æå¸§ {frame.frame_number}ï¼Œå°è¯• {attempt + 1}/{max_attempts}")
                
                # ç¼–ç å›¾åƒ
                try:
                    image_base64 = self.image_service.encode_image_to_base64(frame_path)
                except Exception as e:
                    logger.error(f"å›¾åƒç¼–ç å¤±è´¥: {e}")
                    return None
                
                # ä½¿ç”¨è¿æ¥æ± å’Œä¼šè¯ç®¡ç†
                try:
                    llm = ChatOllama(
                        base_url=self.ollama_url,
                        model=self.model_name,
                        temperature=0.1,
                        timeout=15,  # å›ºå®š15ç§’è¶…æ—¶
                        request_timeout=15,
                        num_predict=256,  # è¿›ä¸€æ­¥é™åˆ¶è¾“å‡ºé•¿åº¦
                        keep_alive=0  # ç«‹å³é‡Šæ”¾èµ„æº
                    )
                    
                    # æç®€åŒ–çš„åˆ†ææç¤º
                    prompt = f"""åˆ†æè¿™ä¸ªè§†é¢‘å¸§(ç¬¬{frame.frame_number}å¸§)ï¼Œç”¨JSONæ ¼å¼å›ç­”:
{{
  "scene": "åœºæ™¯ç±»å‹",
  "objects": ["ç‰©ä½“1", "ç‰©ä½“2"],
  "desc": "ç®€çŸ­æè¿°"
}}"""
                    
                    # æ„å»ºæ¶ˆæ¯
                    messages = [
                        HumanMessage(
                            content=[
                                {"type": "text", "text": prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                            ]
                        )
                    ]
                    
                    # å•ç‹¬çš„è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…æ— é™ç­‰å¾…
                    response = await asyncio.wait_for(
                        llm.ainvoke(messages), 
                        timeout=20  # 20ç§’ç¡¬è¶…æ—¶
                    )
                    
                    if response and response.content:
                        # è§£æå¹¶æ ‡å‡†åŒ–ç»“æœ
                        parsed_result = self._parse_frame_analysis_simple(response.content, frame)
                        if parsed_result:
                            return parsed_result
                    
                    logger.warning(f"å¸§ {frame.frame_number} ç¬¬ {attempt + 1} æ¬¡å°è¯•æ— æ•ˆå“åº”")
                    
                except asyncio.TimeoutError:
                    logger.warning(f"å¸§ {frame.frame_number} ç¬¬ {attempt + 1} æ¬¡å°è¯•è¶…æ—¶")
                    
                except Exception as e:
                    logger.warning(f"å¸§ {frame.frame_number} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                
                # å°è¯•ä¹‹é—´çš„å»¶è¿Ÿ
                if attempt < max_attempts - 1:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                logger.error(f"å¸§ {frame.frame_number} åˆ†æå‡ºç°ä¸¥é‡é”™è¯¯: {e}")
                break
        
        # æ‰€æœ‰å°è¯•å¤±è´¥ï¼Œè¿”å›åŸºç¡€ä¿¡æ¯
        logger.warning(f"å¸§ {frame.frame_number} æ‰€æœ‰åˆ†æå°è¯•å¤±è´¥ï¼Œè¿”å›åŸºç¡€ä¿¡æ¯")
        return {
            "frame_number": frame.frame_number,
            "timestamp": frame.timestamp,
            "scene_type": "unknown",
            "detected_objects": [],
            "visual_themes": [],
            "text_content": "",
            "description": f"å¸§{frame.frame_number}åŸºç¡€ä¿¡æ¯",
            "confidence": 0.1,
            "quality_metrics": {
                "brightness": getattr(frame, 'brightness', 0.5),
                "contrast": getattr(frame, 'contrast', 0.5),
                "sharpness": getattr(frame, 'sharpness', 0.5)
            }
        }
    
    def _parse_frame_analysis_simple(self, analysis_text: str, frame: FrameInfo) -> Optional[Dict[str, Any]]:
        """
        ç®€åŒ–çš„å¸§åˆ†æç»“æœè§£æ
        """
        try:
            import re
            import json
            
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{[^{}]*\}', analysis_text)
            if json_match:
                json_str = json_match.group(0)
                try:
                    data = json.loads(json_str)
                except json.JSONDecodeError:
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•çš„æ–‡æœ¬æå–
                    data = self._extract_from_text(analysis_text)
            else:
                data = self._extract_from_text(analysis_text)
            
            # æ ‡å‡†åŒ–ç»“æœ
            result = {
                "frame_number": frame.frame_number,
                "timestamp": frame.timestamp,
                "scene_type": str(data.get("scene", "unknown"))[:50],  # é™åˆ¶é•¿åº¦
                "detected_objects": self._extract_list(data.get("objects", [])),
                "visual_themes": self._extract_list(data.get("themes", [])),
                "text_content": "",
                "description": str(data.get("desc", ""))[:100],  # é™åˆ¶æè¿°é•¿åº¦
                "confidence": min(float(data.get("confidence", 0.5)), 1.0),
                "quality_metrics": {
                    "brightness": getattr(frame, 'brightness', 0.5),
                    "contrast": getattr(frame, 'contrast', 0.5),
                    "sharpness": getattr(frame, 'sharpness', 0.5)
                }
            }
            
            return result
            
        except Exception as e:
            logger.error(f"è§£æå¸§åˆ†æç»“æœå¤±è´¥: {e}")
            return None
    
    def _extract_from_text(self, text: str) -> dict:
        """ä»æ–‡æœ¬ä¸­æå–åŸºç¡€ä¿¡æ¯"""
        return {
            "scene": "analyzed_scene",
            "objects": ["video_content"],
            "desc": "è§†é¢‘å¸§å†…å®¹"
        }
    
    def _extract_list(self, obj) -> List[str]:
        """å®‰å…¨åœ°æå–åˆ—è¡¨"""
        if isinstance(obj, list):
            return [str(item)[:30] for item in obj[:5]]  # æœ€å¤š5ä¸ªé¡¹ç›®ï¼Œæ¯ä¸ªæœ€å¤š30å­—ç¬¦
        elif isinstance(obj, str):
            return [obj[:30]]
        else:
            return []
    
    async def _generate_video_summary_safe(self, frame_analyses: List[Dict[str, Any]]) -> str:
        """
        å®‰å…¨çš„è§†é¢‘æ‘˜è¦ç”Ÿæˆï¼ŒåŒ…å«é‡è¯•æœºåˆ¶
        """
        if not frame_analyses:
            return "æ— å¸§åˆ†ææ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦"
        
        try:
            # æå–å…³é”®ä¿¡æ¯
            scene_types = set()
            all_objects = set()
            
            for analysis in frame_analyses:
                if analysis.get('scene_type'):
                    scene_types.add(analysis['scene_type'])
                if analysis.get('detected_objects'):
                    all_objects.update(analysis['detected_objects'])
            
            # ç”ŸæˆåŸºäºç»Ÿè®¡çš„æ‘˜è¦
            summary_parts = []
            if scene_types:
                summary_parts.append(f"åœºæ™¯ç±»å‹: {', '.join(list(scene_types)[:3])}")
            if all_objects:
                summary_parts.append(f"ä¸»è¦å¯¹è±¡: {', '.join(list(all_objects)[:5])}")
            
            summary_parts.append(f"å…±åˆ†æ{len(frame_analyses)}ä¸ªå…³é”®å¸§")
            
            return "; ".join(summary_parts)
            
        except Exception as e:
            logger.error(f"è§†é¢‘æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"


# åˆ›å»ºå…¨å±€å®ä¾‹
video_vision_service = VideoVisionService() 