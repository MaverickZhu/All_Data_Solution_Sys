"""
è§†é¢‘åˆ†ææœåŠ¡
æä¾›ä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æã€ç¼©ç•¥å›¾ç”Ÿæˆã€å…ƒæ•°æ®æå–ç­‰åŠŸèƒ½
"""
import logging
import subprocess
import json
from pathlib import Path
from typing import Dict, Any, Optional, List
import cv2
import numpy as np

logger = logging.getLogger(__name__)

class VideoAnalysisService:
    """
    è§†é¢‘åˆ†ææœåŠ¡
    é›†æˆå¤šç§è§†é¢‘åˆ†ææŠ€æœ¯ï¼Œæä¾›å…¨é¢çš„è§†é¢‘å†…å®¹åˆ†æ
    """
    
    def __init__(self):
        self.supported_formats = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v', '.3gp']
        logger.info("ğŸ¬ è§†é¢‘åˆ†ææœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def is_supported_format(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ"""
        return file_path.suffix.lower() in self.supported_formats
    
    def extract_metadata_with_ffprobe(self, video_path: Path) -> Dict[str, Any]:
        """
        ä½¿ç”¨ffprobeæå–è¯¦ç»†çš„è§†é¢‘å…ƒæ•°æ®
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è¯¦ç»†çš„å…ƒæ•°æ®å­—å…¸
        """
        try:
            # ä½¿ç”¨ffprobeè·å–è¯¦ç»†ä¿¡æ¯
            cmd = [
                'ffprobe', '-v', 'quiet', '-print_format', 'json',
                '-show_format', '-show_streams', str(video_path)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                metadata = json.loads(result.stdout)
                
                # æå–æœ‰ç”¨ä¿¡æ¯
                format_info = metadata.get('format', {})
                streams = metadata.get('streams', [])
                
                video_stream = None
                audio_stream = None
                
                for stream in streams:
                    if stream.get('codec_type') == 'video' and not video_stream:
                        video_stream = stream
                    elif stream.get('codec_type') == 'audio' and not audio_stream:
                        audio_stream = stream
                
                enhanced_metadata = {
                    'format_name': format_info.get('format_name', ''),
                    'format_long_name': format_info.get('format_long_name', ''),
                    'duration': float(format_info.get('duration', 0)),
                    'size': int(format_info.get('size', 0)),
                    'bit_rate': int(format_info.get('bit_rate', 0)),
                    'nb_streams': int(format_info.get('nb_streams', 0)),
                    'nb_programs': int(format_info.get('nb_programs', 0)),
                    'tags': format_info.get('tags', {})
                }
                
                if video_stream:
                    # æå–å¸§ç‡
                    fps = 0
                    if video_stream.get('r_frame_rate'):
                        try:
                            fps_str = video_stream.get('r_frame_rate', '0/1')
                            if '/' in fps_str:
                                num, den = fps_str.split('/')
                                fps = float(num) / float(den) if float(den) != 0 else 0
                        except:
                            fps = 0
                    
                    # æå–æ€»å¸§æ•°
                    nb_frames = 0
                    if 'nb_frames' in video_stream:
                        try:
                            nb_frames = int(video_stream['nb_frames'])
                        except (ValueError, TypeError):
                            # å¦‚æœæ— æ³•ä»nb_framesè·å–ï¼Œå°è¯•é€šè¿‡æ—¶é•¿å’Œå¸§ç‡è®¡ç®—
                            if fps > 0 and enhanced_metadata.get('duration'):
                                nb_frames = int(fps * float(enhanced_metadata['duration']))
                    elif fps > 0 and enhanced_metadata.get('duration'):
                        # å¦‚æœæ²¡æœ‰nb_frameså­—æ®µï¼Œé€šè¿‡æ—¶é•¿å’Œå¸§ç‡è®¡ç®—
                        nb_frames = int(fps * float(enhanced_metadata['duration']))
                    
                    enhanced_metadata.update({
                        'width': int(video_stream.get('width', 0)),
                        'height': int(video_stream.get('height', 0)),
                        'fps': fps,
                        'nb_frames': nb_frames,  # æ·»åŠ æ€»å¸§æ•°
                        'video_codec': video_stream.get('codec_name', ''),
                        'video_codec_long': video_stream.get('codec_long_name', ''),
                        'video_profile': video_stream.get('profile', ''),
                        'video_level': video_stream.get('level', ''),
                        'pixel_format': video_stream.get('pix_fmt', ''),
                        'color_space': video_stream.get('color_space', ''),
                        'color_range': video_stream.get('color_range', ''),
                        'field_order': video_stream.get('field_order', ''),
                        'video_bit_rate': int(video_stream.get('bit_rate', 0)) if video_stream.get('bit_rate') else 0,
                        'max_bit_rate': int(video_stream.get('max_bit_rate', 0)) if video_stream.get('max_bit_rate') else 0,
                        'video_tags': video_stream.get('tags', {})
                    })
                
                # æ·»åŠ æ˜¯å¦æœ‰éŸ³é¢‘çš„æ ‡è®°
                enhanced_metadata['has_audio'] = audio_stream is not None
                
                if audio_stream:
                    enhanced_metadata.update({
                        'audio_codec': audio_stream.get('codec_name', ''),
                        'audio_codec_long': audio_stream.get('codec_long_name', ''),
                        'audio_profile': audio_stream.get('profile', ''),
                        'sample_rate': int(audio_stream.get('sample_rate', 0)),
                        'channels': int(audio_stream.get('channels', 0)),
                        'channel_layout': audio_stream.get('channel_layout', ''),
                        'audio_bit_rate': int(audio_stream.get('bit_rate', 0)) if audio_stream.get('bit_rate') else 0,
                        'audio_tags': audio_stream.get('tags', {})
                    })
                
                logger.info(f"ğŸ“Š ffprobeå…ƒæ•°æ®æå–æˆåŠŸ: {video_path.name}")
                return enhanced_metadata
                
            else:
                logger.warning(f"ffprobe failed with return code {result.returncode}: {result.stderr}")
                return {}
                
        except subprocess.TimeoutExpired:
            logger.error(f"ffprobe timeout for {video_path}")
            return {}
        except Exception as e:
            logger.error(f"ffprobe error for {video_path}: {e}")
            return {}
    
    def generate_multiple_thumbnails(self, video_path: Path, count: int = 3) -> List[str]:
        """
        ç”Ÿæˆå¤šä¸ªç¼©ç•¥å›¾ï¼ˆå¼€å§‹ã€ä¸­é—´ã€ç»“æŸï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            count: ç¼©ç•¥å›¾æ•°é‡
            
        Returns:
            ç¼©ç•¥å›¾è·¯å¾„åˆ—è¡¨
        """
        thumbnails = []
        
        try:
            cap = cv2.VideoCapture(str(video_path))
            
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
                return thumbnails
            
            # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            if total_frames <= 0 or fps <= 0:
                logger.error(f"æ— æ³•è·å–è§†é¢‘å¸§ä¿¡æ¯: {video_path}")
                cap.release()
                return thumbnails
            
            # åˆ›å»ºç¼©ç•¥å›¾ç›®å½•
            thumbnails_dir = video_path.parent / "thumbnails"
            thumbnails_dir.mkdir(exist_ok=True)
            
            # è®¡ç®—ç¼©ç•¥å›¾ä½ç½®
            positions = []
            if count == 1:
                positions = [total_frames // 2]  # ä¸­é—´ä½ç½®
            else:
                step = total_frames // (count + 1)
                positions = [step * (i + 1) for i in range(count)]
            
            for i, frame_pos in enumerate(positions):
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
                ret, frame = cap.read()
                
                if ret:
                    # è°ƒæ•´ç¼©ç•¥å›¾å¤§å°
                    h, w = frame.shape[:2]
                    if w > 400:
                        scale = 400 / w
                        new_w, new_h = int(w * scale), int(h * scale)
                        frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
                    
                    # ä¿å­˜ç¼©ç•¥å›¾
                    thumbnail_filename = f"thumb_{video_path.stem}_{i+1}.jpg"
                    thumbnail_path = thumbnails_dir / thumbnail_filename
                    
                    cv2.imwrite(str(thumbnail_path), frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                    thumbnails.append(str(thumbnail_path))
                    
                    logger.info(f"ç”Ÿæˆç¼©ç•¥å›¾ {i+1}/{count}: {thumbnail_path}")
            
            cap.release()
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {e}")
        
        return thumbnails
    
    def analyze_video_content(self, video_path: Path) -> Dict[str, Any]:
        """
        åˆ†æè§†é¢‘å†…å®¹ç‰¹å¾
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å†…å®¹åˆ†æç»“æœ
        """
        try:
            cap = cv2.VideoCapture(str(video_path))
            
            if not cap.isOpened():
                return {"error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"}
            
            # åŸºæœ¬ä¿¡æ¯
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # é‡‡æ ·åˆ†æï¼ˆæ¯ç§’1å¸§ï¼‰
            sample_interval = max(1, int(fps))
            sample_frames = []
            
            frame_count = 0
            brightness_values = []
            contrast_values = []
            
            while frame_count < total_frames:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)
                ret, frame = cap.read()
                
                if not ret:
                    break
                
                # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œåˆ†æ
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                
                # è®¡ç®—äº®åº¦å’Œå¯¹æ¯”åº¦
                brightness = np.mean(gray)
                contrast = np.std(gray)
                
                brightness_values.append(brightness)
                contrast_values.append(contrast)
                
                frame_count += sample_interval
                
                # é™åˆ¶åˆ†æå¸§æ•°ï¼ˆæœ€å¤š100å¸§ï¼‰
                if len(brightness_values) >= 100:
                    break
            
            cap.release()
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            avg_brightness = np.mean(brightness_values) if brightness_values else 0
            avg_contrast = np.mean(contrast_values) if contrast_values else 0
            brightness_std = np.std(brightness_values) if brightness_values else 0
            contrast_std = np.std(contrast_values) if contrast_values else 0
            
            # å†…å®¹ç‰¹å¾åˆ†æ
            content_analysis = {
                "brightness_analysis": {
                    "average": round(avg_brightness, 2),
                    "std_deviation": round(brightness_std, 2),
                    "category": self._categorize_brightness(avg_brightness)
                },
                "contrast_analysis": {
                    "average": round(avg_contrast, 2),
                    "std_deviation": round(contrast_std, 2),
                    "category": self._categorize_contrast(avg_contrast)
                },
                "visual_stability": {
                    "brightness_stability": "ç¨³å®š" if brightness_std < 20 else "ä¸­ç­‰" if brightness_std < 40 else "ä¸ç¨³å®š",
                    "contrast_stability": "ç¨³å®š" if contrast_std < 15 else "ä¸­ç­‰" if contrast_std < 30 else "ä¸ç¨³å®š"
                },
                "analyzed_frames": len(brightness_values),
                "sample_rate": f"æ¯ç§’{1}å¸§" if sample_interval == fps else f"æ¯{sample_interval}å¸§é‡‡æ ·1æ¬¡"
            }
            
            logger.info(f"ğŸ¯ è§†é¢‘å†…å®¹åˆ†æå®Œæˆ: {video_path.name}")
            return content_analysis
            
        except Exception as e:
            logger.error(f"è§†é¢‘å†…å®¹åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _categorize_brightness(self, brightness: float) -> str:
        """åˆ†ç±»äº®åº¦çº§åˆ«"""
        if brightness < 50:
            return "è¾ƒæš—"
        elif brightness < 100:
            return "ä¸­ç­‰"
        elif brightness < 150:
            return "è¾ƒäº®"
        else:
            return "å¾ˆäº®"
    
    def _categorize_contrast(self, contrast: float) -> str:
        """åˆ†ç±»å¯¹æ¯”åº¦çº§åˆ«"""
        if contrast < 20:
            return "ä½å¯¹æ¯”åº¦"
        elif contrast < 40:
            return "ä¸­ç­‰å¯¹æ¯”åº¦"
        elif contrast < 60:
            return "é«˜å¯¹æ¯”åº¦"
        else:
            return "æé«˜å¯¹æ¯”åº¦"
    
    def comprehensive_analysis(self, video_path: Path) -> Dict[str, Any]:
        """
        ç»¼åˆè§†é¢‘åˆ†æ
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ¬ å¼€å§‹ç»¼åˆè§†é¢‘åˆ†æ: {video_path.name}")
            
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            if not self.is_supported_format(video_path):
                return {"error": f"ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼: {video_path.suffix}"}
            
            # åŸºç¡€åˆ†æç»“æœ
            analysis_result = {
                "analysis_type": "video_enhanced",
                "file_path": str(video_path),
                "file_size": video_path.stat().st_size,
                "format": video_path.suffix[1:].lower()
            }
            
            # 1. æå–è¯¦ç»†å…ƒæ•°æ®
            ffprobe_metadata = self.extract_metadata_with_ffprobe(video_path)
            if ffprobe_metadata:
                analysis_result["enhanced_metadata"] = ffprobe_metadata
            
            # 2. ç”Ÿæˆå¤šä¸ªç¼©ç•¥å›¾
            thumbnails = self.generate_multiple_thumbnails(video_path, count=3)
            if thumbnails:
                analysis_result["thumbnails"] = thumbnails
                analysis_result["primary_thumbnail"] = thumbnails[0]
            
            # 3. å†…å®¹åˆ†æ
            content_analysis = self.analyze_video_content(video_path)
            if "error" not in content_analysis:
                analysis_result["content_analysis"] = content_analysis
            
            # 4. ç”Ÿæˆåˆ†ææ‘˜è¦
            analysis_result["analysis_summary"] = self._generate_analysis_summary(analysis_result)
            
            logger.info(f"âœ… ç»¼åˆè§†é¢‘åˆ†æå®Œæˆ: {video_path.name}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"ç»¼åˆè§†é¢‘åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _generate_analysis_summary(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        summary = {}
        
        # åŸºæœ¬ä¿¡æ¯æ‘˜è¦
        enhanced_metadata = analysis_result.get("enhanced_metadata", {})
        if enhanced_metadata:
            duration = enhanced_metadata.get("duration", 0)
            size_mb = analysis_result.get("file_size", 0) / (1024 * 1024)
            
            summary.update({
                "duration_formatted": f"{int(duration // 60)}åˆ†{int(duration % 60)}ç§’",
                "file_size_mb": round(size_mb, 2),
                "video_codec": enhanced_metadata.get("video_codec", "æœªçŸ¥"),
                "audio_codec": enhanced_metadata.get("audio_codec", "æœªçŸ¥"),
                "has_audio": bool(enhanced_metadata.get("audio_codec")),
                "bit_rate_kbps": round(enhanced_metadata.get("bit_rate", 0) / 1000, 0) if enhanced_metadata.get("bit_rate") else 0
            })
        
        # å†…å®¹åˆ†ææ‘˜è¦
        content_analysis = analysis_result.get("content_analysis", {})
        if content_analysis:
            brightness = content_analysis.get("brightness_analysis", {})
            contrast = content_analysis.get("contrast_analysis", {})
            
            summary.update({
                "visual_quality": f"{brightness.get('category', 'æœªçŸ¥')}ï¼Œ{contrast.get('category', 'æœªçŸ¥')}",
                "content_stability": content_analysis.get("visual_stability", {}).get("brightness_stability", "æœªçŸ¥")
            })
        
        # ç¼©ç•¥å›¾ä¿¡æ¯
        thumbnails = analysis_result.get("thumbnails", [])
        summary["thumbnails_count"] = len(thumbnails)
        
        return summary

# åˆ›å»ºå…¨å±€å®ä¾‹
video_analysis_service = VideoAnalysisService() 